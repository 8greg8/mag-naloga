\chapter{Implementacija metod}
V tem poglavju so opisane implementacije nekaterih metod, opisanih v poglavju~\ref{sec:metode}. Gre za tiste metode, kjer iz teoreti캜ne podlage implementacija ni bila to캜no razvidna. Opisane so tudi metode, ki nimajo teoreti캜ne podlage, saj gre samo za specifi캜no implementacijo.

\subsection{Opti캜ni in prostorski tok}
Na podlagi opisanih lastnosti metod opti캜nega toka v poglavju~\ref{sec:metode-of} smo se odlo캜ili, da bomo v tem delu uporabili diferencialno metodo. Kljub vi코ji ra캜unski zahtevnosti, ki ob dana코nji tehnologiji ne predstavlja ve캜 takega problema, smo 쬰leli ra캜unati gost opti캜ni tok. Z gostim opti캜nim tokom dobimo natan캜no aproksimacijo polja gibanja za celotno telo. Prav tako nimamo problemov pri estimaciji energijske porabe za hitre gibe, kot bi bilo to v primeru uporabe ujemalnih metod. Ker je glavni namen uporaba in ne implementacija diferencialne metode, smo se osredoto캜ili na Farneb{\"a}ck algoritem, ki je dostopen v knji쬹ici OpenCV 3.1.0.

Za opti캜ni tok smo uporabili slede캜e parametre: piramidna skala $pyr\_scale=\num{0.5}$, 코tevilo piramidnih slojev $levels=3$, velikost okna povpre캜enja $winsize=15$, 코tevilo iteracij na vsakem piramidnem sloju $iterations=3$, velikost okolice slikovnih elementov $poly\_n=5$ in Gaussov standardni odklon $poly\_sigma=\num{1.2}$.

Z uporabo prostorskega toka lahko bolje opi코emo mehani캜no delo kot pri uporabi opti캜nega toka. Vsekakor pa potrebujemo dodatno informacijo, ki jo moramo pridobiti iz slikovnih podatkov. Za ta namen smo uporabili t.i. ``Time-of-Flight'' (ToF) kamere, ki so vgrajene v poceni Microsoft Kinect for Windows V2 senzor~\cite{Yang2015KinectV2}. Z njim pridobivamo registrirane RGB-D (rde캜e, zelene, modre in globinske) podatke. Za pridobitev prostorskega toka smo uporabili PD-Flow algoritem. Njegova implementacija je javno dostopna~\cite{jaimez2015primal}. Podrobneje je opisan v poglavju~\ref{sec:pd-flow}.



\subsection{Sledilniki}
Pri izbiri sledilnikov smo se osredoto캜ili na pogoje, ki jim morajo sledilniki v najve캜ji meri zadostiti. Sledilnik mora dobro slediti osebam, ostali objekti niso pomembni. Sledenje mora biti zanesljivo, saj je od njega odvisna merilna napaka. Pri tem moramo upo코tevati delovanje tudi v primerih, kadar tar캜a izgine iz slike. Sledenje mora delovati 캜im dalj코i 캜as tako, da ne potrebujemo ponovne inicializacije. Inicializacijo sledilnika moramo opraviti samo na prvi sliki zaporedja, kar pomeni, da mora sledilnik vsebovati indirektno u캜enje (angl. offline training). Zaradi uporabe sledilnika v merilnem instrumentu mora ta delovati 캜im hitreje. Ker namen tega dela ni implementacija sledilnika, mora biti ta implementiran v prosto dostopni izvorni kodi. 

Pri uporabi opti캜nega toka smo najprej preizkusili sledilnik TLD avtorja Kalal et al.~\cite{kalal2012tracking}. Prosto dostopne so tri implementacije sledilnika, in sicer v knji쬹ici ccv (CCV-TLD), v knji쬹ici OpenCV (OPENCV-TLD) in c++ izvorna koda (NEBEHAY-TLD). Implementaciji iz knji쬹ic ccv in OpenCV se nekoliko razlikujeta od izvirnega dela~\cite{kalal2012tracking}, NEBEHAY-TLD pa je samo prepis Matlabove izvorne kode.  Ker ni nobena implementacija zadovoljivo delovala na testnih squash posnetkih, smo poskusili 코e s sledilnikoma KCF~\cite{danelljan2014adaptive} in DLIB-CORR~\cite{danelljan2014accurate}. KCF je implementiran v knji쬹ici OpenCV, DLIB-CORR pa v knji쬹ici Dlib~\cite{king2009dlib}.

Testiranje sledilnikov je opisano v poglavju~\ref{sec:testiranje-sledilnikov-za-opticni-tok}, rezultati pa v poglavju~\ref{sec:rezultati-sledilnikov-za-opticni-tok}. Ugotovili smo, da najbolje deluje sledilnik KCF. Tega smo tudi uporabili v na코ih nadaljnjih eksperimentih.

Pri uporabi prostorskega toka smo preizkusili in uporbili DS-KCF sledilnik avtorja Hannuna et. al~\cite{hannuna2016ds}. Sledilnik uporablja RGB in globinske slike.


Rezultat sledenja je pri obeh uporabljenih sledilnikih (KCF in DS-KCF) okvir opazovanega subjekta. Notranjost okvirja uporabljamo za zapolnitev histogramov v deskriptorjih, preostanek toka v prizori코캜u zavr쬰mo. Algoritma sledenja smo potrebovali za terenske teste, kjer polo쬬j igralca ni znan. Kljub skrbni izbiri algoritmov je to najmanj robusten del na코ega pristopa---캜e sledilnik za posamezen 캜asovni interval ne detektira igralca, manjkajo podatki na tem intervalu, razen 캜e smo sledenje nadzorovali in odpravljali napake. Sledilnik ne detektira igralca kadar:

\begin{itemize}
	\item{Algoritem signalizira, da ni zaznal tar캜e.}
	\item{Algoritem signalizira nizko zaupanje v rezultat (predvsem zaradi okluzij).}
	\item{Povr코ina podro캜ja tar캜e je 0.}
	\item{Vsi vektorji opti캜nega ali prostorskega toka so ni캜elni znotraj podro캜ja tar캜e.}
\end{itemize}

Na코 pristop je dovolj modularen, da lahko enostavno zamenjamo algoritme za sledenje. S kakr코nimi koli napredki na podro캜ju vizualnega sledenja se bo zanesljivost na코e metode izbolj코ala.

\subsection{Kalmanov filter}\label{sec:implementacija-kalman}
Za prostor stanj smo izbrali stanje hitrosti $v$ in pospe코ka $a$~\eqref{eq:stanje}. 

\begin{equation}
\vec{x}(k) = \begin{bmatrix}
					v(k) & a(k)
				\end{bmatrix}^\top 
                \label{eq:stanje}
\end{equation}

Matrika prehajanja stanj je dolo캜ena z ena캜bo~\eqref{eq:a}.

\begin{equation}
\vec{A} = \begin{bmatrix}
				1 & 1 \\
                0 & 1
			\end{bmatrix} 
            \label{eq:a}
\end{equation}

Za matriko vhodnih stanj $G$ smo izbrali~\eqref{eq:g}, s katero modeliramo neznane vhodne parametre hitrosti $v_n$ in pospe코ka $a_n$ v vektorju $u$~\eqref{eq:u}. 

\begin{equation}
\vec{G} = \begin{bmatrix}
				1 & 0
			\end{bmatrix}^\top 
            \label{eq:g}
\end{equation}

\begin{equation}
\vec{u}(k) = \begin{bmatrix}
					v_{n}(k) & a_n(k)
				\end{bmatrix}^\top 
                \label{eq:u}
\end{equation}


Merilna matrika je predstavljena z ena캜bo~\eqref{eq:h}
\begin{equation}
\vec{H} = \begin{bmatrix}
				1 & 0
			\end{bmatrix}^\top 
            \label{eq:h}
\end{equation}

Za za캜etno hitrost in pospe코ek smo izbrali vrednost $0$, ker se na코i testi ve캜inoma za캜nejo v mirovanju. 

Variance 코uma modela gibanja, merilnega modela in kovarian캜ne matrike stanja smo dolo캜ili z uporabo mre쬹ega iskanja, ki je opisan v poglavju~\ref{sec:optimizacija-svm-parametrov}. Pri tem smo uporabili labele u캜nih vzorcev vseh testov 1. sklopa eksperimentov za referenco, njihove po코umljene ocene pa za meritev. Varianca 코uma merilnega modela je tako zna코ala $\sigma_\vec{z}^2 = \num{0.04}$, varianca 코uma modela gibanja pa $\sigma_\vec{x}^2 = \num{456.13}$. Za kovarian캜no matriko predikcije smo uporabili varianco $\sigma_\vec{P}^2 = \num{456.13}$. Kovarian캜no matriko modela gibanja smo dolo캜ili po ena캜bi~\eqref{eq:Q}, kovarian캜na matrika merilnega modela je bila dolo캜ena z ena캜bo~\eqref{eq:R} in za캜etna vrednost kovarian캜ne matrike stanja z~\eqref{eq:P}.

\begin{equation}
\vec{Q} = \vec{G} \vec{G}^\top \sigma_\vec{x}^2
\label{eq:Q}
\end{equation}

\begin{equation}
\vec{R} = \sigma_\vec{z}^2
\label{eq:R}
\end{equation}

\begin{equation}
\vec{P}(0) = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix} \sigma_\vec{P}^2
\label{eq:P}
\end{equation}










\subsection{Gaussov filter}\label{sec:implementacija-gauss}

Gaussov filter smo implementirali po ena캜bi~\eqref{eq:gauss}. Za velikost jedra smo dolo캜ili $3\sigma$, pri 캜emer je standardni odklon $\sigma$ parameter. Jedro smo nato 코e normirali na vsoto $1$. 

Za filtriranje podatkov smo uporabili modificirano Matlabovo funkcijo \texttt{nanconv}, ki je podrobneje predstavljena v~\cite{kraus2017nanconv}. Namesto funkcije \texttt{conv2} smo v modifikaciji uporabili funkcijo \texttt{conv}.






\subsection{Zdru쬰vanje slik iz dveh Kinect kamer}
Zaradi ozkega vidnega polja Kinect kamer smo za pokritje celotne 코irine igri코캜a potrebovali dve kameri. Zaporedja slik smo pred nadaljnjo obdelavo morali zdru쬴ti v eno zaporedje glede na opazovanega igralca. Zajem iz posameznih kamer ni bil sinhroniziran, zato smo pred zdru쬰vanjem sinhronizirali posnetka tako, da smo izbrali slike iz posameznega zaporedja z najbolj podobnimi 캜asovnimi 쬴gi. 캛asovno sinhornizirana zaporedja slik smo nato posku코ali zdru쬴ti s tremi razli캜nimi metodami:  zdru쬰vanje z zna캜ilkami, zdru쬰vanje s kontrolnimi to캜kami in prilagojeno zdru쬰vanje. 

캛asovno sinhronizirana zaporedja slik smo naprej posku코ali zdru쬴ti z metodo panoramskega 코ivanja slik z uporabo zna캜ilk, kot je opisano v delu~\cite{brown2007automatic}. Tu smo namesto SIFT zna캜ilk uporabili SURF zna캜ilke.
Zdru쬰vanje s zna캜ilkami se ni obneslo, zato smo to metodo opustili. Primer neuspelega poskusa je prikazan na sliki~\ref{fig:zdruzevanje-znacilke}.

\begin{figure}[!htb]
	\centering
	\begin{subfigure}[t]{0.45\columnwidth}
		\includegraphics[width=\columnwidth]{./Slike/matched-features.png}
		\caption{Ujemajo캜e SURF zna캜ilke}
		\label{fig:zdruzevanje-surf}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.45\columnwidth}
		\includegraphics[width=\columnwidth]{./Slike/features-calibration-result.png}
		\caption{Rezultat zdru쬰vanja z zna캜ilkami}
		\label{fig:zdruzevanje-result}
	\end{subfigure}
	\caption[Neuspelo zdru쬰vanje slik s SURF zna캜ilkami]{Primer neuspelega poskusa zdru쬰vanja slik iz dveh Kinect kamer s SURF zna캜ilkami.}
	\label{fig:zdruzevanje-znacilke}
\end{figure}

Zaporedja slik smo posku코ali zdru쬴ti tudi z ro캜nim dolo캜evanjem kontrolnih to캜k. Rezultat {zdru쬰vanja s kontrolnimi to캜kami} je bil bolj코i od zdru쬰vanja z zna캜ilkami, vendar 코e vedno slab, zato smo tudi to metodo opustili. Primer neuspelega poskusa je prikazan na sliki~\ref{fig:zdruzevanje-cp}.

\begin{figure}[!htb]
	\centering
	\begin{subfigure}[t]{0.45\columnwidth}
		\includegraphics[width=\columnwidth]{matched-points.png}
		\caption{Ujemajo캜e kontrolne to캜ke}
		\label{fig:zdruzevanje-ujemajoce-cp}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.45\columnwidth}
		\includegraphics[width=\columnwidth]{points-calibration-result.png}
		\caption{Rezultat zdru쬰vanja s kontrolnimi to캜kami}
		\label{fig:zdruzevanje-result-cp}
	\end{subfigure}
	\caption[Neuspelo zdru쬰vanje slik s kontrolnimi to캜kami]{Primer neuspelega poskusa zdru쬰vanja slik iz dveh Kinect kamer s kontolnimi to캜kami.}
	\label{fig:zdruzevanje-cp}
\end{figure}

Zaradi nezadovoljivih rezultatov klasi캜nih metod zdru쬰vanja stereo slik smo razvili metodo, ki je prilagojena za Kinect kamere. Iz kamer smo z uporabo knji쬹ice libfreenect2 0.2~\cite{lingzhu2016libfreenect2} pridobili intrinzi캜ne parametre bli룙je-infrarde캜ega (NIR) senzorja, in sicer: slikovni koordinati gori코캜ne razdalje $f_u$ in $f_v$ ter slikovni koordinati opti캜nega sredi코캜a slike (ang. principal point) $c_u$ in $c_v$. Intrinzi캜ne parametre smo uporabili za dolo캜itev intrinzi캜ne matrike $\vec{M}_{int}$ po ena캜bi~\eqref{eq:intrinsic}.

Ker pravih ekstrinzi캜nih parametrov kamer nismo poznali, smo jih le ocenili z metodo dolo캜evanja se캜i코캜a vidnih polj obeh kamer. Se캜i코캜e je prikazano kot rde캜a linija na sliki~\ref{fig:zdruzevanje}. S to metodo smo dolo캜ili translacijski vektor $\vec{t} = \left [ t_x~ t_y~ t_z \right]^\top$ in rotacijsko matriko $\vec{R}$ iz Eulerjevih kotov.

S sledenjem igralca z DS-KCF algoritmom smo s pomo캜jo projekcijske matrike~\eqref{eq:projection-matrix} dolo캜ili center tar캜e v metri캜nih enotah za vsako sliko zaporedja leve in desne kamere. 캛e center tar캜e ni vseboval podatkov globine, smo za center izbrali najbli쬵o to캜ko z veljavno globino.

Prva slika zdru쬰nega zaporedja je bila slika kamere, kjer se igralec prvi캜 pojavi. Nadaljnje slike smo izbirali med zaporedjema kamer, glede na pozicijo centra tar캜e s histerezo, ki je na sliki~\ref{fig:zdruzevanje} prikazana z modrimi linijami. Pogled spremenimo samo takrat, ko center tar캜e pre캜ka linijo histereze na igri코캜u. Razdalja med modrima 캜rtama je zna코ala \SI{400}{mm}.


\begin{figure}[!htb]
	\centering
	\includegraphics[width=\columnwidth]{zdruzevanje-example.png}
	\caption[Dolo캜evanje se캜i코캜a vidnih polj leve in desne Kinect kamere]{Dolo캜evanje se캜i코캜a vidnih polj leve in desne Kinect kamere. Na sliki sta prikazani prvi sliki zaporedja leve in desne Kinect kamere 1. seta 2. igre terenskega eksperimenta iz 2. faze. Ozna캜en je 4. igralec. Zelena barva koordinat centra tar캜e predstavlja izbrano kamero. Kamera z rumeno barvo ni izbrana. Se캜i코캜e je rde캜a linija. Modri liniji sta pragova za preklop med kamerama. Razdalja med njima je \SI{400}{mm}.}
	\label{fig:zdruzevanje}
\end{figure}

